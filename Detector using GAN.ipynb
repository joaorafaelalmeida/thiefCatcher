{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import argparse\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "from sklearn import svm\n",
    "# Loading relevant libraries and the dataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore',category=RuntimeWarning)\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "global maximum\n",
    "maximum={}\n",
    "\n",
    "minimumAlert=5\n",
    "showChartBool=True\n",
    "latex=(not showChartBool)\n",
    "\n",
    "obsWindows=[32, 64]\n",
    "slidingValue=16\n",
    "featuresIndex=None#Used to filter for some features\n",
    "window=64 #or 32\n",
    "\n",
    "datasets={\n",
    "    \"train\":{\n",
    "        \"normal\":\"datasets/train/normal.txt\"\n",
    "    },\n",
    "    \"test\":{\n",
    "        \"normal\":\"datasets/test/normal.txt\",\n",
    "        \"brute_isolated\":\"datasets/test/brute_isolated.txt\",\n",
    "        \"brute_mixed\":\"datasets/test/brute_mixed.txt\",\n",
    "        \"smooth_isolated\":\"datasets/test/smooth_isolated.txt\",\n",
    "        \"smooth_mixed\":\"datasets/test/smooth_mixed.txt\",\n",
    "        \"intelligent\":\"datasets/test/intelligent.txt\"\n",
    "    },\n",
    "    \"validation\":{\n",
    "        \"normal\":\"datasets/validation/normal.txt\",\n",
    "        \"brute_isolated\":\"datasets/validation/brute_isolated.txt\",\n",
    "        \"brute_mixed\":\"datasets/validation/brute_mixed.txt\",\n",
    "        \"smooth_isolated\":\"datasets/validation/smooth_isolated.txt\",\n",
    "        \"smooth_mixed\":\"datasets/validation/smooth_mixed.txt\",\n",
    "        \"intelligent\":\"datasets/validation/intelligent.txt\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractStats(data):\n",
    "    nSamp,nCols=data.shape\n",
    "\n",
    "    M1=np.mean(data,axis=0)\n",
    "    Md1=np.median(data,axis=0)\n",
    "    Std1=np.std(data,axis=0)\n",
    "    \n",
    "    features=np.hstack((M1,Md1,Std1))\n",
    "    return(features)\n",
    "\n",
    "def extratctSilenceActivity(data,threshold=0):\n",
    "    if(data[0]<=threshold):\n",
    "        s=[1]\n",
    "        a=[]\n",
    "    else:\n",
    "        s=[]\n",
    "        a=[1]\n",
    "    for i in range(1,len(data)):\n",
    "        if(data[i-1]>threshold and data[i]<=threshold):\n",
    "            s.append(1)\n",
    "        elif(data[i-1]<=threshold and data[i]>threshold):\n",
    "            a.append(1)\n",
    "        elif (data[i-1]<=threshold and data[i]<=threshold):\n",
    "            s[-1]+=1\n",
    "        else:\n",
    "            a[-1]+=1\n",
    "    return(s,a)\n",
    "    \n",
    "def extractStatsSilenceActivity(data):\n",
    "    features=[]\n",
    "    nSamples,nMetrics=data.shape\n",
    "    silence_features=np.array([])\n",
    "    activity_features=np.array([])\n",
    "    for c in range(0, nMetrics, 2): #Use only one column from upload and another from download\n",
    "        silence,activity=extratctSilenceActivity(data[:,c],threshold=0)\n",
    "        \n",
    "        if len(silence)>0:\n",
    "            silence_faux=np.array([len(silence),np.mean(silence),np.std(silence)])\n",
    "        else:\n",
    "            silence_faux=np.zeros(3)\n",
    "        silence_features=np.hstack((silence_features,silence_faux))\n",
    "        \n",
    "        if len(activity)>0:\n",
    "            activity_faux=np.array([len(activity),np.mean(activity),np.std(activity)])\n",
    "        else:\n",
    "            activity_faux=np.zeros(3)\n",
    "        activity_features=np.hstack((activity_features,activity_faux))\t   \n",
    "    features=np.hstack((silence_features,activity_features))\n",
    "    return(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: slidingMultObsWindow\n",
    "This function returns all the extracted features. The return is a dict containing the windows size (as key) and the list of features extracted from that windows (as value).\n",
    "Index of the features in the array:\n",
    "1. Window of 32 seconds:\n",
    "    1. Mean (4 columns: Upload Size, Upload Count, Download Size, Download Count)\n",
    "    2. Median (4 columns: Upload Size, Upload Count, Download Size, Download Count)\n",
    "    3. Standard deviation (4 columns: Up Size, Up Count, Down Size, Down Count)\n",
    "    4. Silence (6 columns: Mean, Median and Standard deviation for Upload and Download size)\n",
    "    5. Activity (6 columns: Mean, Median and Standard deviation for Upload and Download size)\n",
    "1. Window of 64 seconds:\n",
    "    1. Mean (4 columns: Upload Size, Upload Count, Download Size, Download Count)\n",
    "    2. Median (4 columns: Upload Size, Upload Count, Download Size, Download Count)\n",
    "    3. Standard deviation (4 columns: Up Size, Up Count, Down Size, Down Count)\n",
    "    4. Silence (6 columns: Mean, Median and Standard deviation for Upload and Download size)\n",
    "    5. Activity (6 columns: Mean, Median and Standard deviation for Upload and Download size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slidingMultObsWindow(data,lengthObsWindow,slidingValue, filterIndex=None, defineMax=False):\n",
    "    nSamples,nMetrics=data.shape\n",
    "    #Fix windows\n",
    "    results = {}\n",
    "    for s in np.arange(max(lengthObsWindow),nSamples,slidingValue):\n",
    "        features=np.array([])\n",
    "        for oW in lengthObsWindow:\n",
    "            if oW not in results:\n",
    "                results[oW] = []\n",
    "            subdata=data[s-oW:s,1:]\n",
    "            faux=extractStats(subdata)\n",
    "            faux2=extractStatsSilenceActivity(subdata)\n",
    "            features=np.hstack((features,faux,faux2))\n",
    "            #print(('{} '*len(features)).format(*features))\n",
    "            if filterIndex:\n",
    "                features = features[filterIndex]\n",
    "            results[oW].append(features)\n",
    "    \n",
    "    for oW in lengthObsWindow:\n",
    "        if oW in results:\n",
    "            results[oW] = np.array(results[oW])\n",
    "            global maximum\n",
    "            if defineMax:\n",
    "                maximum[oW]=(results[oW].max(axis=0)+np.finfo(np.float32).eps)\n",
    "            results[oW] = results[oW]/maximum[oW]\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showChart(dataInput):\n",
    "    if showChartBool:\n",
    "        name=dataInput.split(\"/\")[1:3]\n",
    "        print(\"Traffic from\", name[0], \"in\", name[1], \"mode\")\n",
    "        corruptData=np.loadtxt(dataInput,dtype=int)\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.plot(corruptData[:,0],corruptData[:,1],corruptData[:,0],corruptData[:,3])\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Packages count')\n",
    "        plt.subplot(2,1,2)\n",
    "        plt.plot(corruptData[:,0],corruptData[:,2],corruptData[:,0],corruptData[:,4])\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Packages count')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileInput=datasets[\"train\"][\"normal\"]\n",
    "showChart(fileInput)\n",
    "data=np.loadtxt(fileInput,dtype=int)\n",
    "normalTraffic = slidingMultObsWindow(data,obsWindows,slidingValue, featuresIndex, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic={}\n",
    "for x in datasets:\n",
    "    traffic[x]={}\n",
    "    for ds in datasets[x]:\n",
    "        fin=datasets[x][ds]\n",
    "        data=np.loadtxt(fin,dtype=int)\n",
    "        showChart(fin)\n",
    "        traffic[x][ds] = slidingMultObsWindow(data,obsWindows,slidingValue, featuresIndex)[window]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "Xtrain=traffic[\"train\"][\"normal\"]\n",
    "torch.manual_seed(111)\n",
    "train_data_length = len(Xtrain)\n",
    "train_data = torch.from_numpy(Xtrain)\n",
    "train_labels = torch.zeros(train_data_length)\n",
    "train_set = [\n",
    "    (train_data[i], train_labels[i]) for i in range(train_data_length)\n",
    "]\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24626543640>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_data[:, 0], train_data[:, 1], \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(48, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 48),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "\n",
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "num_epochs = 300\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for n, (real_samples, _) in enumerate(train_loader):\n",
    "        # Data for training the discriminator\n",
    "        new_batch_size=len(real_samples)\n",
    "        real_samples_labels = torch.ones((new_batch_size, 1))\n",
    "        latent_space_samples = torch.randn((new_batch_size, 2))#, dtype=torch.float64)\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "        generated_samples_labels = torch.zeros((new_batch_size, 1))\n",
    "        \n",
    "        all_samples = torch.cat((real_samples, generated_samples))\n",
    "        all_samples_labels = torch.cat(\n",
    "            (real_samples_labels, generated_samples_labels)\n",
    "        )\n",
    "        \n",
    "        # Training the discriminator\n",
    "        discriminator.zero_grad()\n",
    "        output_discriminator = discriminator(all_samples.float())\n",
    "        loss_discriminator = loss_function(\n",
    "            output_discriminator, all_samples_labels)\n",
    "        loss_discriminator.backward()\n",
    "        optimizer_discriminator.step()\n",
    "\n",
    "        # Data for training the generator\n",
    "        latent_space_samples = torch.randn((new_batch_size,  2))\n",
    "\n",
    "        # Training the generator\n",
    "        generator.zero_grad()\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "        \n",
    "        output_discriminator_generated = discriminator(generated_samples)\n",
    "        loss_generator = loss_function(\n",
    "            output_discriminator_generated, real_samples_labels\n",
    "        )\n",
    "        loss_generator.backward()\n",
    "        optimizer_generator.step()\n",
    "\n",
    "        # Show loss\n",
    "        if epoch % 10 == 0 and False:\n",
    "            print(f\"Epoch: {epoch} Loss D.: {loss_discriminator}\")\n",
    "            print(f\"Epoch: {epoch} Loss G.: {loss_generator}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate traffic\n",
    "latent_space_samples = torch.randn(512, 2)\n",
    "generated_samples = generator(latent_space_samples)\n",
    "dtset = generated_samples.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(prediction, botWindow):\n",
    "    TP=0.00001\n",
    "    FP=0.00001\n",
    "    FN=0.00001\n",
    "    pIndex=0\n",
    "    for p in prediction:\n",
    "        if pIndex in botWindow:\n",
    "            if p == -1:\n",
    "                TP+=1\n",
    "            else:\n",
    "                FN+=1\n",
    "        else:\n",
    "            if p == -1:\n",
    "                FP+=1\n",
    "            else:\n",
    "                TP+=1\n",
    "        pIndex+=1\n",
    "    try:\n",
    "        precision=TP/(TP+FP)\n",
    "        recall=TP/(TP+FN)\n",
    "        f1=2*((precision*recall)/(precision+recall))\n",
    "    except:\n",
    "        return None, None, None\n",
    "    return precision, recall, f1\n",
    "\n",
    "def process(dataInput, botWindow, algorithm=\"svm\"):\n",
    "    data=np.loadtxt(dataInput,dtype=int)\n",
    "    traffic = slidingMultObsWindow(data,obsWindows,slidingValue, featuresIndex)[window]\n",
    "    name=dataInput.split(\"/\")[1:3]\n",
    "    showChart(dataInput)\n",
    "    \n",
    "    if algorithm == \"svm\":\n",
    "        prediction = clf.predict(traffic)\n",
    "    elif algorithm == \"kmeans\":\n",
    "        prediction=[]\n",
    "        for obs in traffic:\n",
    "            dists = euclidean_distances([obs],kmeans.cluster_centers_)\n",
    "            if dists[0]>maxDst+thresholdKmeans:\n",
    "                prediction+=[-1]\n",
    "            else:\n",
    "                prediction+=[1]\n",
    "    elif algorithm == \"pca_svm\":\n",
    "        pcaFeatures = pca.fit(traffic).transform(traffic)\n",
    "        prediction = clf.predict(pcaFeatures)\n",
    "\n",
    "    count=0\n",
    "    numPositives=0\n",
    "    pIndex=0\n",
    "    countAlerts=0\n",
    "    for value in prediction:\n",
    "        if value == 1:\n",
    "            numPositives+=1\n",
    "            if numPositives >= 2:\n",
    "                count=0\n",
    "                numPositives=0\n",
    "        else:\n",
    "            count+=1\n",
    "        if count>=minimumAlert:\n",
    "            countAlerts+=1\n",
    "        pIndex+=1\n",
    "    precision, recall, f1=scores(prediction,botWindow)\n",
    "    \n",
    "    if latex:\n",
    "        print(\"& &\", round(precision, 2), \"&\", round(recall, 2), \"&\", round(f1, 2), \"&\", countAlerts)\n",
    "    else:  \n",
    "        print(\"Traffic from\", name[0], \"in\", name[1], \"mode\")\n",
    "        print(prediction)\n",
    "        print(\"Scores:\")\n",
    "        print(name[0], \"in\", name[1], \"mode\", \"Precision:\", round(precision, 2), \"Recall:\", round(recall, 2), \"F1-Score:\", round(f1, 2), \"Alert (%):\", countAlerts/(pIndex-minimumAlert+1)*100)\n",
    "        print(\"Num Alerts:\", countAlerts)\n",
    "        print(\"Alert (%):\", countAlerts/(pIndex-minimumAlert+1)*100)\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(gamma='auto', nu=0.001)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=np.concatenate((Xtrain,dtset), axis=0)\n",
    "clf = svm.OneClassSVM(nu=0.001, kernel=\"rbf\", gamma='auto')\n",
    "clf.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& & 0.85 & 1.0 & 0.92 & 0\n",
      "& & 1.0 & 1.0 & 1.0 & 11\n",
      "& & 1.0 & 0.74 & 0.85 & 17\n",
      "& & 1.0 & 0.67 & 0.8 & 2\n",
      "& & 1.0 & 0.14 & 0.25 & 0\n",
      "& & 1.0 & 0.41 & 0.58 & 0\n"
     ]
    }
   ],
   "source": [
    "valFiles=[(datasets[\"validation\"][\"normal\"], [-1]), \n",
    "            (datasets[\"validation\"][\"brute_isolated\"], range(0, 500)), #500, because all traffic contains bot\n",
    "            (datasets[\"validation\"][\"brute_mixed\"], range(3, 500)), #First minute does not contain bot, so due to the sliding scale, the bot is considered after 3 windows\n",
    "            (datasets[\"validation\"][\"smooth_isolated\"], range(0, 500)), #500, because all traffic contains bot\n",
    "            (datasets[\"validation\"][\"smooth_mixed\"], range(3, 500)), #First minute does not contain bot, so due to the sliding scale, the bot is considered after 3 windows\n",
    "            (datasets[\"validation\"][\"intelligent\"], range(3, 500)), #First minute does not contain bot, so due to the sliding scale, the bot is considered after 3 windows\n",
    "           ]\n",
    "for dataInput, botWin in valFiles:\n",
    "    process(dataInput, botWin, \"svm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& & 0.93 & 1.0 & 0.96 & 0\n",
      "& & 1.0 & 1.0 & 1.0 & 10\n",
      "& & 1.0 & 0.2 & 0.33 & 0\n",
      "& & 1.0 & 0.6 & 0.75 & 4\n",
      "& & 1.0 & 0.23 & 0.38 & 0\n",
      "& & 1.0 & 0.21 & 0.35 & 0\n"
     ]
    }
   ],
   "source": [
    "testFiles=[(datasets[\"test\"][\"normal\"], [-1]), \n",
    "            (datasets[\"test\"][\"brute_isolated\"], range(0, 500)), #500, because all traffic contains bot\n",
    "            (datasets[\"test\"][\"brute_mixed\"], range(3, 500)), #First minute does not contain bot, so due to the sliding scale, the bot is considered after 3 windows\n",
    "            (datasets[\"test\"][\"smooth_isolated\"], range(0, 500)), #500, because all traffic contains bot\n",
    "            (datasets[\"test\"][\"smooth_mixed\"], range(3, 500)), #First minute does not contain bot, so due to the sliding scale, the bot is considered after 3 windows\n",
    "            (datasets[\"test\"][\"intelligent\"], range(3, 500)), #First minute does not contain bot, so due to the sliding scale, the bot is considered after 3 windows\n",
    "           ]\n",
    "for dataInput, botWin in testFiles:\n",
    "    process(dataInput, botWin, \"svm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17447553 0.4114031  0.47764827 0.5381942  0.10155107 0.41542431\n",
      " 0.43900036 0.55131881 0.22181069 0.35891877 0.37403391 0.39583336\n",
      " 0.22542595 0.14278547 0.12984385 0.21756225 0.15305082 0.1367825\n",
      " 0.28863796 0.30529019 0.34382967 0.28016937 0.31514052 0.33513985\n",
      " 0.22036476 0.46966913 0.56692548 0.6394573  0.06723988 0.49463442\n",
      " 0.4497392  0.58794779 0.2882053  0.4857376  0.48604423 0.50711888\n",
      " 0.35671883 0.33521378 0.25878368 0.34430653 0.34398104 0.27430199\n",
      " 0.39179708 0.32466331 0.28324961 0.37938478 0.3350758  0.28451993]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "kmeans = KMeans(n_clusters=1, random_state=0).fit(Xtrain)\n",
    "print(kmeans.cluster_centers_[0])\n",
    "#dists = euclidean_distances(kmeans.cluster_centers_)\n",
    "\n",
    "maxDst=0\n",
    "for obs in Xtrain:\n",
    "    dists = euclidean_distances([obs],kmeans.cluster_centers_)\n",
    "    if dists[0]>maxDst:\n",
    "        maxDst=dists[0]\n",
    "thresholdKmeans=maxDst*0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& & 0.85 & 1.0 & 0.92 & 0\n",
      "& & 1.0 & 1.0 & 1.0 & 11\n",
      "& & 1.0 & 0.59 & 0.74 & 13\n",
      "& & 0.5 & 0.0 & 0.0 & 0\n",
      "& & 1.0 & 0.11 & 0.19 & 0\n",
      "& & 1.0 & 0.35 & 0.52 & 0\n"
     ]
    }
   ],
   "source": [
    "valFiles=[(datasets[\"validation\"][\"normal\"], [-1]), \n",
    "            (datasets[\"validation\"][\"brute_isolated\"], range(0, 500)), #500, because all traffic contains bot\n",
    "            (datasets[\"validation\"][\"brute_mixed\"], range(3, 500)), #First minute does not contain bot, so due to the sliding scale, the bot is considered after 3 windows\n",
    "            (datasets[\"validation\"][\"smooth_isolated\"], range(0, 500)), #500, because all traffic contains bot\n",
    "            (datasets[\"validation\"][\"smooth_mixed\"], range(3, 500)), #First minute does not contain bot, so due to the sliding scale, the bot is considered after 3 windows\n",
    "            (datasets[\"validation\"][\"intelligent\"], range(3, 500)), #First minute does not contain bot, so due to the sliding scale, the bot is considered after 3 windows\n",
    "           ]\n",
    "for dataInput, botWin in valFiles:\n",
    "    process(dataInput, botWin, \"kmeans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& & 1.0 & 1.0 & 1.0 & 0\n",
      "& & 1.0 & 1.0 & 1.0 & 10\n",
      "& & 1.0 & 0.2 & 0.33 & 0\n",
      "& & 0.5 & 0.0 & 0.0 & 0\n",
      "& & 1.0 & 0.23 & 0.38 & 0\n",
      "& & 1.0 & 0.21 & 0.35 & 0\n"
     ]
    }
   ],
   "source": [
    "testFiles=[(datasets[\"test\"][\"normal\"], [-1]), \n",
    "            (datasets[\"test\"][\"brute_isolated\"], range(0, 500)), #500, because all traffic contains bot\n",
    "            (datasets[\"test\"][\"brute_mixed\"], range(3, 500)), #First minute does not contain bot, so due to the sliding scale, the bot is considered after 3 windows\n",
    "            (datasets[\"test\"][\"smooth_isolated\"], range(0, 500)), #500, because all traffic contains bot\n",
    "            (datasets[\"test\"][\"smooth_mixed\"], range(3, 500)), #First minute does not contain bot, so due to the sliding scale, the bot is considered after 3 windows\n",
    "            (datasets[\"test\"][\"intelligent\"], range(3, 500)), #First minute does not contain bot, so due to the sliding scale, the bot is considered after 3 windows\n",
    "           ]\n",
    "for dataInput, botWin in testFiles:\n",
    "    process(dataInput, botWin, \"kmeans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "gan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
